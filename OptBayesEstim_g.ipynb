{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem2: Optimal Bayesian Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0- First Some Data Pre-Processing\n",
    "\n",
    "- At this moment you should have \"train_PCA.pkl\" and \"test_PCA.pkl\" files in your working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "train_data=pickle.load(open( \"train_PCA.pkl\", \"rb\" ),encoding ='latin1')\n",
    "test_data=pickle.load(open( \"test_PCA.pkl\", \"rb\" ),encoding ='latin1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism',\n",
    "              'talk.religion.misc',\n",
    "              'comp.graphics',\n",
    "              'sci.space']\n",
    "\n",
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio  = 0.1 \n",
    "e=math.e\n",
    "L = [e**-25, e**-20, e**-15, e**-10, e**-5,0,1,2,3, e**5, e**10] # range of lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Train data into Train and Validation (Ratio Train : Val = 4:1)\n",
    "\n",
    "train_num = int(train_data['data'].shape[0]*(1.0-val_ratio)) \n",
    "val_num = -1*int(train_data['data'].shape[0]*val_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data and Train Target\n",
    "#Validation data and Validation Target\n",
    "\n",
    "\n",
    "train_feature = train_data['data'][:train_num]\n",
    "train_target = train_data['target'][:train_num]\n",
    "\n",
    "val_feature = train_data['data'][val_num:]\n",
    "val_target = train_data['target'][val_num:]\n",
    "\n",
    "test_feature = test_data['data']\n",
    "test_target = test_data['target']\n",
    "test_num = test_data['data'].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1353"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1830,)\n",
      "(203,)\n"
     ]
    }
   ],
   "source": [
    "# shape of data set\n",
    "\n",
    "print(train_target.shape)\n",
    "print(val_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Find Mean and Prior for Estimating Multivariate Normal Dist. for Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean and prior (which is just the frequency)\n",
    "mu = np.zeros([train_feature.shape[1],len(categories)], dtype=float)\n",
    "Pi = np.zeros(len(categories),dtype=float)\n",
    "\n",
    "for i in range(len(train_target)):\n",
    "    Pi[train_target[i]] += 1\n",
    "    mu[:,train_target[i]] += train_feature[i]\n",
    "\n",
    "\n",
    "for j in range(4):\n",
    "    mu[:,j] = mu[:,j]/Pi[j]\n",
    "\n",
    "Pi = Pi/len(train_feature)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500,)\n",
      "(1500,)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(mu[:,0]))\n",
    "print (np.shape(test_feature[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Build Models For Several Cases\n",
    "\n",
    "For each case consider the followings:\n",
    "\n",
    "\n",
    "- First, compute the covariance matrix (name it cov)\n",
    "\n",
    "- Build the Multivariate Normal dist. based on the computed mean and cov.\n",
    "\n",
    "- Then build the Model\n",
    "\n",
    "- Report the Confusion Matrix, ROC and plot the data scatter and the decision boundaries in 2D (so based on top-2 PCA features). For the Confusion matrix and ROC, use Scilearn built in functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *Case 0: multivariate normals with shared spherical variances:*\n",
    " \n",
    "- In this case, first compute the cov to be a diagonal matrix with the same element on diag which is the average of the feasure variances, i.e. sum(diag(cov(x)))/2*eye(2), x is the data point matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = sum(np.diag(np.cov(train_feature.T)))/1500*np.eye(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_shared(cov):    \n",
    "    sigma=sum(np.diag(np.cov(train_feature.T)))/1500\n",
    "\n",
    "    w=np.zeros([len(categories),train_feature.shape[1]],dtype=float)\n",
    "    w0=np.zeros(len(categories),dtype=float)\n",
    "    g=np.zeros([len(categories),train_feature.shape[1]],dtype=float)\n",
    "    for i in range(4):\n",
    "        mu_=mu[:,i]\n",
    "        w[i]=np.divide(mu_,sigma)\n",
    "        w0[i]=1.0/(2*sigma)* np.matmul(mu_, mu_)+ np.log(Pi[i])\n",
    "\n",
    "    prediction = []\n",
    "\n",
    "    for i in range(len(test_feature)):\n",
    "        g=np.zeros(4,dtype=float)\n",
    "        for c in range(4):\n",
    "            g[c]=np.matmul(w[c],test_feature[i])+w0[c]\n",
    "        prediction.append(np.argmax(g))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import sklearn.preprocessing\n",
    "def draw_plt(num):\n",
    "    label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "    label_binarizer.fit(range(4))\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "\n",
    "    test_vectorized = label_binarizer.transform(test_target)\n",
    "    y =  label_binarizer.transform(prediction)\n",
    "\n",
    "    for i in range(4):\n",
    "        fpr[i], tpr[i], _ = roc_curve(test_vectorized[:,i],y[:,i]) # i column\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    print (\"roc accuracy:\")\n",
    "    print (roc_auc)\n",
    "    \n",
    "    lw = 2\n",
    "    for i in range(4):\n",
    "        plt.figure()\n",
    "        plt.plot(fpr[i], tpr[i], color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic example_group'+str(i))\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        filename=\"Q6_case\"+num+\"_ROC_\"+str(i)+\".png\"\n",
    "        plt.savefig(filename)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f2a750d4ad0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_class_pca\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_class_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmu_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_class' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=2)\n",
    "pca.fit(train_feature)\n",
    "train_pca=pca.transform(train_feature)\n",
    "train_class_pca=dict()\n",
    "for i in range(4):\n",
    "    train_class_pca[i]=pca.transform(train_class[i])\n",
    "mu_pca = np.zeros([2,len(categories)], dtype=float)\n",
    "for c in range(4):\n",
    "    mu_pca[:,c]=np.mean(train_class_pca[c],axis=0).transpose()\n",
    "cov_pca=np.cov(train_pca.transpose())\n",
    "sigma_pca=sum(np.diagonal(cov_pca))/2\n",
    "w_p=np.zeros([len(categories),2],dtype=float)\n",
    "w0_p=np.zeros(len(categories),dtype=float)\n",
    "for i in range(4):\n",
    "    mu_p=mu_pca[:,i]\n",
    "    w_p[i]=np.divide(mu_p,sigma_pca)\n",
    "    w0_p[i]=1.0/(2*sigma_pca)* np.matmul(mu_p, mu_p)+ np.log(Pi[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pred_shared(cov)\n",
    "print (\"confusion matrix:\")\n",
    "print (confusion_matrix(prediction, test_target))\n",
    "draw_plt('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Case 1: multivariate normals with shared axis parellel variances:*\n",
    "\n",
    "- In this case, first compute the cov to be the diagonal matrix with the variance of each feasure on the diag, i.e. diag(diag(cov(x)))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.diag(np.diag(np.cov(train_feature.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "cov_inv = np.linalg.inv(cov)\n",
    "for i in range(len(test_feature)):\n",
    "    mx = -1\n",
    "    idx = -1\n",
    "    for j in range(len(categories)):\n",
    "        y = test_feature[i] - mu[:,j]\n",
    "        y = np.dot(np.dot(y.T,cov_inv),y)\n",
    "        y = math.exp(-0.5*y)*Pi[j]\n",
    "        if y > mx:\n",
    "            mx = y\n",
    "            idx = j\n",
    "    prediction.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(prediction, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Case 2: multivariate normals with shared arbitrary variances:*\n",
    "\n",
    "- In this case, first compute cov to be the general covariance matrix of feasures, i.e. cov(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.cov(train_feature.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "cov_inv = np.linalg.inv(cov)\n",
    "for i in range(len(test_feature)):\n",
    "    min = 10000000\n",
    "    idx = -1\n",
    "    for j in range(4):\n",
    "        y = test_feature[i] - mu[:,j]\n",
    "        y = np.dot(np.dot(y.T,cov_inv),y)\n",
    "#         y = math.exp(-0.5*y)\n",
    "        if y < min:\n",
    "            min = y\n",
    "            idx = j\n",
    "    prediction.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(prediction, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Case 3: multivariate normals with shared spherical variances:*\n",
    "\n",
    "- In this case, first compute a cov for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = np.zeros([train_feature.shape[1],train_feature.shape[1],len(categories)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(categories)):\n",
    "    train_special_feature = []\n",
    "    for tar in train_target:\n",
    "        if tar == i :\n",
    "            train_special_feature.append(train_feature[:,i])\n",
    "    cov\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 4: Same as case 3, but with reject option. Threshold 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
